<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>maGaming RSS Feed - gamedeveloper_com</title>
        <link>https://lukasz-gladek-av.github.io/custom-rss/gamedeveloper_com.xml</link>
        <description>A cleaned-up version of the original gaming feed for gamedeveloper_com</description>
        <lastBuildDate>Mon, 24 Nov 2025 17:57:53 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <item>
            <title><![CDATA[Are Roblox and Discord protected from civil liability under Section 230?]]></title>
            <link>https://www.gamedeveloper.com/business/are-roblox-and-discord-protected-from-civil-liability-under-section-230-</link>
            <guid>https://www.resetera.com/threads/are-roblox-and-discord-protected-from-civil-liability-under-section-230.1363075/</guid>
            <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div data-component="captioned-content" data-testid="featured-image"><p><span>Image by FAMILY STOCK via Adobe Stock</span></p></div><div data-module="content" data-testid="article-base-body-content"><p data-testid="content-paragraph"><span data-testid="content-text"><span>Content note: This story contains discussions of children being propositioned for sexual actions and receiving sexual messages, as well as self-harm.</span></span></p><p data-testid="content-paragraph"><span data-testid="content-text">How liable are </span><span data-testid="content-text"><span>Roblox</span></span><span data-testid="content-text"> developer Roblox Corporation. and communications platform Discord for illegal conduct by users on their platforms?</span></p><p data-testid="content-paragraph"><span data-testid="content-text">That's the question both companies face in </span><span data-testid="content-text"><a target="_self" href="https://www.gamedeveloper.com/business/roblox-discord-sued-for-facilitating-the-sexual-exploitation-of-a-minor">a growing suite of lawsuits,</a></span><span data-testid="content-text"> many filed by law firm </span><span data-testid="content-text"><a target="_blank" href="https://www.anapolweiss.com/">Anapol Weiss</a></span><span data-testid="content-text">. The firm represents a number of families whose children were targeted by predators on </span><span data-testid="content-text"><span>Roblox</span></span><span data-testid="content-text">. Some of these predators encouraged these minors to communicate with them over Discord to sexually exploited them first electronically, then physically.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">The lawsuits follow </span><span data-testid="content-text"><a target="_blank" href="https://youtu.be/vTMF6xEiAaY?si=guY2FRmxyAZziZTh">years of reporting</a></span><span data-testid="content-text"> on how </span><span data-testid="content-text"><span>Roblox</span></span><span data-testid="content-text">'s allegedly lax moderation protocols have seemingly enabled child exploitation through a combination of lax age identification protocols the hosting of </span><span data-testid="content-text"><a target="_self" href="https://www.gamedeveloper.com/business/roblox-report-inflated-user-numbers-child-predator-presence-investors">sexually explicit user-made games</a></span><span data-testid="content-text">. Roblox Corp. and Discord have </span><span data-testid="content-text"><a target="_blank" href="https://corp.roblox.com/newsroom/2025/09/roblox-to-expand-age-estimation-to-all-users">both introduced</a></span><span data-testid="content-text"> a number of </span><span data-testid="content-text"><a target="_self" href="https://www.gamedeveloper.com/business/discord-rolls-out-new-teen-safety-and-moderation-tools-for-guardians">safety improvements</a></span><span data-testid="content-text"> in the last year (with Roblox unveiling </span><span data-testid="content-text"><a target="_self" href="https://www.gamedeveloper.com/business/roblox-will-soon-enforce-age-checks-to-limit-conversations-between-minors-and-adults">new age check measures</a></span><span data-testid="content-text"> landing just this month), but according to </span><span data-testid="content-text"><a target="_blank" href="https://www.businesswire.com/news/home/20231107766120/en/Multiple-Families-Sue-Roblox-Corporation-for-Exploiting-Children-Online">some plaintiffs</a></span><span data-testid="content-text">, the companies should have done more to protect users years ago.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">Last week when quizzed about this topic, Roblox Corp. CEO David Baszucki </span><span data-testid="content-text"><a target="_self" href="https://www.gamedeveloper.com/business/roblox-ceo-clashes-with-reporters-when-pressed-about-child-safety">grew combative</a></span><span data-testid="content-text"> with New York Times reporters, pushing back on repeated questions about the company's safety record.</span></p><p data-component="related-article"><span data-testid="related-article-title">Related:</span><a href="https://www.gamedeveloper.com/business/roblox-ceo-clashes-with-reporters-when-pressed-about-child-safety" target="_self" data-discover="true">Roblox CEO clashes with reporters when pressed about child safety</a></p><p data-testid="content-paragraph"><span data-testid="content-text">Both companies have repeatedly denied any lax practices. And they're heading to court with case law seemingly tilted in their favor. That's because of a federal law known as the </span><span data-testid="content-text"><a target="_blank" href="https://www.congress.gov/crs-product/R46751">Communications Decency Act</a></span><span data-testid="content-text">. But with the safety of so many young players on the line, it's worth asking—how does the law apply to these companies?</span></p><h2 data-testid="content-text" id="Section 230 broadly shields companies that host user-generated content">Section 230 broadly shields companies that host user-generated content</h2><p data-testid="content-paragraph"><span data-testid="content-text">First passed in 1934, the law was updated in 1996 and hosts a clause known as "Section 230," which provides limited federal immunity to "providers and users of interactive computer services." It's </span><span data-testid="content-text"><a target="_blank" href="https://www.pbs.org/newshour/politics/what-you-should-know-about-section-230-the-rule-that-shaped-todays-internet">shielded</a></span><span data-testid="content-text"> telecommunication companies and social media platforms from legal liability for content hosted by its users. For instance if someone on Facebook falsely accuses you of a crime, you can sue that user defamation, but not Facebook owner Meta.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">These companies also offer civil immunity for removing obscene or terms-of-service-violating content from their platforms from their platforms—even constitutionally protected speech—so long as that removal is done "in good faith." The law does not provide immunity for criminal violations, state civil laws, and other instances. That may mean it doesn't apply to suits filed by the states of </span><span data-testid="content-text"><a target="_self" href="https://www.gamedeveloper.com/business/florida-state-launches-criminal-investigation-into-roblox">Florida</a></span><span data-testid="content-text">, </span><span data-testid="content-text"><a target="_self" href="https://www.gamedeveloper.com/business/roblox-corp-responds-to-louisiana-lawsuit-that-claims-it-built-the-perfect-place-for-pedophiles-">Louisiana</a></span><span data-testid="content-text">, and </span><span data-testid="content-text"><a target="_self" href="https://www.gamedeveloper.com/business/roblox-corp-sued-by-state-of-texas-for-allegedly-platforming-pedophiles">Texas</a></span><span data-testid="content-text">.</span></p><p data-component="related-article"><span data-testid="related-article-title">Related:</span><a href="https://www.gamedeveloper.com/business/ubisoft-s-first-playable-generative-ai-experience-is-an-r-d-experiment-called-teammates-" target="_self" data-discover="true">Ubisoft's first playable generative AI experience is an R&amp;D experiment called 'Teammates'</a></p><p data-testid="content-paragraph"><span data-testid="content-text">Cases like </span><span data-testid="content-text"><a target="_blank" href="https://www.eff.org/issues/cda230/cases/jane-doe-v-america-online-inc">Jane Doe v. America Online Inc.</a></span><span data-testid="content-text"> and M.A. v. </span><span data-testid="content-text"><a target="_blank" href="https://www.eff.org/issues/cda230/cases/ma-v-village-voice-media">Village Voice</a></span><span data-testid="content-text"> have laid out precedent relative to the lawsuits against Roblox Corp. and Discord. In both cases, the defendants were accused of aiding and abetting the sexual abuse of minors, but Federal courts ruled the companies possessed civil immunity under Section 230.</span></p><h2 data-testid="content-text" id="Plaintiffs' lawyers suing Roblox and Discord say this isn't about hosted content">Plaintiffs' lawyers suing Roblox and Discord say this isn't about hosted content</h2><p data-testid="content-paragraph"><span data-testid="content-text">Alexandra Walsh, an Anapol Weis lawyer representing parents suing the company, told Game Developer her firm took on with the intent of "giving victims a voice," a motivation that's "at the heart" of the firm. "What started as a few complaints has ballooned into a wave of litigation as families across the country realize they are victims of the same systemic failures by Roblox and Discord to protect their children," she said.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">According to Walsh, Section 230 is "irrelevant" to her clients' claims. "Roblox will invoke it and has invoked it because every tech company automatically invokes it when they get sued," she said. "But they are grossly-overinterpreting the application of that statute. In our view, that statue is designed to do is to limit liability in cases where an internet service provider is...publishing someone else's material."</span></p><p data-component="related-article"><span data-testid="related-article-title">Related:</span><a href="https://www.gamedeveloper.com/business/report-savvy-games-group-s-saudi-owned-parent-fund-is-running-low-on-investable-cash" target="_self" data-discover="true">Report: Savvy Games Group's Saudi-owned parent fund is running low on investable cash</a></p><p data-testid="content-paragraph"><span data-testid="content-text">She described how the firm's cases center on how these apps are released without adequate safety features while purportedly misrepresenting a their safety protections for underage users. Adult predators were able to create profiles signaling that they were children, and children were able to sign up for accounts without going to their parents.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">Game developers might recognize however, that the phenomenon of underage users signing up for online games or services without a parent's permission is as old as...well, the internet. When asked about this, Walsh said there was a distinction in how other platforms like Instagram have "some attempt" to enforce their age minimum policies, and how </span><span data-testid="content-text"><span>Roblox</span></span><span data-testid="content-text"> provides minimal friction for when underage users sign up for the platform.&nbsp;</span></p><p data-testid="content-paragraph"><span data-testid="content-text">"We're not saying that any particular measure is going to be perfect 100% of the time," she said in allusion to age-gates that might, for example, require a parent's email address to create an account. "But at least it's some friction...at least it's making some kids pause."</span></p><p data-testid="content-paragraph"><span data-testid="content-text">Walsh said it's "easy" for kids on Discord to turn parental controls off without their parents' knowledge. Predators take advantage of this capability to lure their targets into lowering protective barriers. A better system might be one that automatically notifies parents when these controls are turned off.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">The two platforms are linked through </span><span data-testid="content-text"><span>Roblox</span></span><span data-testid="content-text">'s Discord integration. The Florida-based predator who abused Ethan Dallas—the child of one of Walsh's clients—reportedly lured Dallas off of </span><span data-testid="content-text"><span>Roblox</span></span><span data-testid="content-text"> and into Discord where he was able to further sexually exploit the teenager.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">Dallas died by suicide in April 2024.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">"</span><span data-testid="content-text"><span>Roblox</span></span><span data-testid="content-text"> is a gaming platform that is heavily marketed and promoted as being safe and appropriate for children," Walsh said. "At the same time, the company knows that every day, child predators are coming on the platform." She referred to regular reports that Roblox Corporation makes to the Center for Missing and Exploited Children, as well as </span><span data-testid="content-text"><a target="_blank" href="https://www.bloomberg.com/features/2024-roblox-pedophile-problem/">news stories</a></span><span data-testid="content-text"> covering the arrests of predators who targeted minors on their platform as evidence of this fact.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">Yet despite all that </span><span data-testid="content-text"><span>Roblox</span></span><span data-testid="content-text"> and Discord may still be protected by Section 230 in these civil cases.</span></p><h2 data-testid="content-text" id="Proving Section 230 doesn't apply could prove difficult">Proving Section 230 doesn't apply could prove difficult</h2><p data-testid="content-paragraph"><span data-testid="content-text">Electronic Frontier Foundation attorney Aaron Mackey—director of the nonprofit's free speech and transparency litigation efforts—acknowledged it's challenging to differentiate between responsibility and liability when it comes to protecting kids online. The Foundation has </span><span data-testid="content-text"><a target="_blank" href="https://ilt.eff.org/Defamation__CDA_Cases.html">been a strong advocate for Section 230</a></span><span data-testid="content-text">, arguing that while some elements of the Communication Decency Act were flawed, the law has provided vital protections for freedom of speech on the internet.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">Mackey declined to comment on the specifics of the cases against Roblox Corp. and Discord. But in a conversation with Game Developer, he explained communication platforms of all stripes have been repeatedly found not liable for abusive messages sent on their platform because of Section 230. It may sound counterintuitive, but these protections enable the existence of </span><span data-testid="content-text"><span>any</span></span><span data-testid="content-text"> online moderation.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">Before Section 230's existence, internet service providers CompuServe and Prodigy both faced lawsuits for their policies about moderating what users posted on their servers. The former company said it would not moderate any content, while Prodigy said it would. Both were sued, and Prodigy was the one to be found liable for content hosted on its servers even though it was the one with a moderation policy.&nbsp;</span></p><p data-testid="content-paragraph"><span data-testid="content-text">Mackey said the law was created to let services to decide for themselves about what kind of speech to allow on their platform, and offer protections when they enforced those policies. That raises the bar for civil suits about messages sent between users.&nbsp;</span></p><p data-testid="content-paragraph"><span data-testid="content-text">There appear to also be protections for generic promises about child safety on </span><span data-testid="content-text"><span>Roblox</span></span><span data-testid="content-text"> and Discord. "There are cases in which plaintiffs have tried to raise this claim, which is that they're not seeking to hold [platforms] liable for the content of the communication but for representations about what they would do to protect users," he said. "Those cases have not succeeded."</span></p><p data-testid="content-paragraph"><span data-testid="content-text">The courts have also ruled that Section 230 provides immunity for claims that cover the account creation process. "The courts ruled that 230 applied because the services decision to offer public accounts was inherently connected with the ability for account holders to create, view, share content on the service," Mackey said. "A legal claim that sought to change or limit the service’s ability to have the account-creation process it wanted would implicate 230 because it necessarily seeks to impose liability based on the third-party content on the site.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">The cases that have succeeded centered on specific promises made by online platforms to specific users. Mackey recalled a case reviewed by the Ninth Circuit about a user who faced online abuse, asked the platform owner for help, was promised assistance, and then the company took action. The Court ruled that section 230 did not apply to the case because it involved the failure of a service to follow through on its promise.</span></p><h2 data-testid="content-text" id="How can online platforms improve child safety?">How can online platforms improve child safety?</h2><p data-testid="content-paragraph"><span data-testid="content-text">It's tempting to view Section 230 as an obstacle for holding online platforms accountable for user safety—but there's a larger patchwork of policy gaps that led to this complicated status quo. Law enforcement has been slow to act on all manner of online threats. The closed ecosystems or </span><span data-testid="content-text"><span>Roblox</span></span><span data-testid="content-text"> and Discord prevent other companies from offering third-party safety tools to parents. And laws shaped around online "child safety" have been sharply criticized for their </span><span data-testid="content-text"><a target="_blank" href="https://www.eff.org/deeplinks/2025/11/surveillance-mandate-disguised-child-safety-why-guard-act-wont-keep-us-safe">potential</a></span><span data-testid="content-text"> to block all manner of undesired speech.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">Pair that with a </span><span data-testid="content-text"><a target="_blank" href="https://www.marketingdive.com/news/meta-reduced-content-moderation-brand-safety/736779/">global retreat</a></span><span data-testid="content-text"> in </span><span data-testid="content-text"><a target="_blank" href="https://fortune.com/2024/02/06/inside-elon-musk-x-twitter-austin-content-moderation/">online moderation</a></span><span data-testid="content-text"> and you </span><span data-testid="content-text"><a target="_blank" href="https://www.cbc.ca/news/entertainment/youtube-content-moderation-rules-1.7559931">create</a></span><span data-testid="content-text"> a porous online ecosystem that stops some predators—but lets others slip through the cracks. "A general industry trend of scaling back moderation would be an abhorrent excuse for putting children in harm’s way," Walsh said to Game Developer.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">"Other companies have successfully implemented common-sense safety mechanisms like ID age verification, &nbsp;mandatory parental approval by default, and robust deterrents to prevent messaging between children and adults. Corporations marketing themselves as child-friendly have a non-negotiable responsibility to prioritize child safety."</span></p><p data-testid="content-paragraph"><span data-testid="content-text">When reached for comment, a Discord spokesperson declined to discuss on the specifics of these cases and if they planned to invoke Section 230 in their defense. "We use a combination of advanced technology and trained safety teams to proactively find and remove content that violates our policies," they said.</span></p><p data-testid="content-paragraph"><span data-testid="content-text">Roblox Corp. did not respond to multiple requests for comment.</span></p></div><div><h2>About the Author</h2><div data-component="contributor-summary"><p data-testid="contributor-summary-subtitle">Senior Editor, GameDeveloper.com</p><div><p data-testid="content-paragraph"><span data-testid="content-text">Bryant Francis is a writer, journalist, and narrative designer based in Boston, MA. He currently writes for Game Developer, a leading B2B publication for the video game industry. His credits include Proxy Studios' upcoming 4X strategy game Zephon and Amplitude Studio's 2017 game Endless Space 2.</span></p></div></div></div></div><br/><br/>https://www.gamedeveloper.com/business/are-roblox-and-discord-protected-from-civil-liability-under-section-230-]]></content:encoded>
        </item>
    </channel>
</rss>