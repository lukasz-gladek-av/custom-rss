<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>maGaming RSS Feed - theverge_com</title>
        <link>https://lukasz-gladek-av.github.io/custom-rss/theverge_com.xml</link>
        <description>A cleaned-up version of the original gaming feed for theverge_com</description>
        <lastBuildDate>Thu, 29 Jan 2026 18:45:16 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <item>
            <title><![CDATA[Half of developers think gen AI is bad for the gaming industry]]></title>
            <link>https://www.theverge.com/entertainment/869386/ai-game-development-gdc-survey</link>
            <guid>1420117</guid>
            <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div id="zephr-anchor"><p>While generative AI is being adopted at various levels of game development, a new survey suggests that developers increasingly think the technology is bad for the industry. According to the most recent survey from the Game Developers Conference, 52 percent of respondents said that gen AI is having a “negative” impact on the games industry, versus just 7 percent who viewed the technology as “positive.” Perhaps most startling is how the negative outlook has grown over the years: in 2024, just 18 percent of those surveyed viewed the tech as a negative, and that number jumped to 30 percent in 2025. Now it’s up to more than half.</p><p>GDC surveyed 2,300 “game industry professionals” to get these results, and the demographics are primarily male (64 percent), white (67 percent), and based in the United States (54 percent). The organizers admit that this makeup is “far from truly representative of the global community, and we know more work is needed.” (You can check out <a href="https://reg.gdconf.com/2026-SOTI">the full report right here</a>.)</p><p>However, the results still provide some fascinating insight into how actual developers feel about the AI, at the same time that the leaders of <a href="https://www.theverge.com/news/805777/ea-stability-ai-transformative-game-development-tools">major publishers like EA</a> and <a href="https://www.theverge.com/news/805509/krafton-pubg-ai-first-developer-agentic-gpu-cluster">Krafton are espousing its virtues</a> (and as Larian has had to clarify <a href="https://www.theverge.com/games/859551/baldurs-gate-3-larian-studios-gen-ai-concept-art-reddit-ama">how it’s using the technology</a>). As for how much the gen AI is actually being used in the industry, 36 percent of those surveyed said they utilize it as part of their jobs, while 64 percent said they don’t. The majority of those who do use gen AI said they use the tech for research and brainstorming (81 percent), as well as administrative tasks like email (47 percent). But some did admit to using AI for more development-oriented tasks, including prototyping (35 percent), testing or debugging (22 percent), and asset generation (19 percent). Only 5 percent of that group said they use gen AI on “player-facing features.”</p><p>The other major topic broached in the survey was the persistent <a href="https://www.theverge.com/24009039/video-game-layoffs-2023">layoffs and studio closures</a> that have ravaged the industry over the last few years. In the 2025 survey, <a href="https://www.theverge.com/2025/1/22/24349728/gdc-state-of-the-industry-survey-2025-results">one in 10 developers said they had been laid off within the last year</a>. This year, the numbers were similar, with 17 percent of respondents saying they had been laid off in the last 12 months, while a whopping 28 percent had been laid off within the last two years. Naturally, this had led to an aura of uncertainty; 23 percent of those surveyed said that they expected more layoffs in the next year, while 30 percent are unsure.</p><p>The survey also questioned a small number of those in the educational space — more than 100 educators and 50 students, according to GDC — and unsurprisingly the outlook isn’t very positive. 60 percent of those surveyed said that they expect the current state of the industry to make it difficult for new students to get jobs. “Most of my students will not have a career in game development,” said one anonymous educator in Michigan.</p><p>GDC itself kicks off this year on March 9th in San Francisco, and it’s likely these two issues will be a major topic throughout.</p><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li id="follow-author-article_footer-dmcyOmF1dGhvclByb2ZpbGU6MTk3"><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span><span>Andrew Webster</span></span></span></li><li></li><li></li><li></li><li></li></ul></div></div></div><br/><br/>https://www.theverge.com/entertainment/869386/ai-game-development-gdc-survey]]></content:encoded>
            <dc:creator>invalid@example.com (ResetEra_Newsbot</dc:creator>
        </item>
        <item>
            <title><![CDATA[Google’s AI helped me make bad Nintendo knockoffs]]></title>
            <link>https://www.theverge.com/news/869726/google-ai-project-genie-3-world-model-hands-on</link>
            <guid>1420114</guid>
            <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div id="zephr-anchor"><p>This week, a new generative AI tool from Google let me create bad knockoffs of 3D Nintendo worlds.</p><p>Check out my version of something like <em>Super Mario 64</em>:</p><p>I didn’t like <em>Metroid Prime 4: Beyond</em>, but it’s better than my version of a <em>Metroid Prime</em> experience:</p><p>Or how about my take on <em>The Legend of Zelda</em>:<em> Breath of the Wild</em>, complete with a paraglider (and, briefly, a second Link):</p><p>It was all possible thanks to Project Genie, an experimental research prototype that Google gave me access to this week, though I don’t think I’m using it in exactly the way Google intended.</p><p>Google DeepMind has been putting a lot of effort into building its AI “world” models that can generate virtual interactive spaces with text or images as prompts. The company announced its impressive-looking Genie 3 model <a href="https://www.theverge.com/news/718723/google-ai-genie-3-model-video-game-worlds-real-time">last year</a>, but it was only available as “a limited research preview” at the time. Project Genie, which will be rolling out to Google AI Ultra subscribers in the US starting today, will be the first opportunity for more people to actually try out what Genie 3 is capable of.</p><p>Google is releasing Project Genie now partly because it wants to see how people use it. “It’s really for us to actually learn about new use cases that we hadn’t thought about,” Diego Rivas, a product manager at Google DeepMind, tells <em>The Verge</em>. The company is already excited about how Genie could help to visualize scenes for filmmaking or for interactive educational media. You could, if you wanted, take a photo of your kids’ favorite toy and use it to prompt a Genie-generated world. Genie could potentially help robots navigate the real world, too. But Project Genie isn’t yet an “end-to-end product that we expect people to just use every day,” stressed Shlomi Fruchter, a Google DeepMind research director.</p><p>With Project Genie, you pick from a bunch of worlds designed by Google or define prompts for the environments and characters you want to create in your own world. After a brief wait, Genie first generates a thumbnail, then you can have it generate the world. You can explore each generated world for 60 seconds, and each has a resolution of about 720p and a frame rate of about 24fps. While you’re in one, you can (typically) move your character with the WASD keys, jump or go higher with a tap of your space bar, and turn the camera with arrow keys.</p><p>One of Google’s worlds, called “Rollerball,” features a blue orb in a white, snowy world, and as you roll around, the orb leaves a trail of paint behind it. As a “game,” Project Genie wasn’t great. There was nothing to do but roll around; there weren’t any objectives or goals. There was no sound. There was frustrating input lag that was even worse than what I sometimes experience with cloud gaming. (Some of this could be due to the generally poor Wi-Fi I get in my office.)</p><p>Over the course of the 60-second experience, Genie sometimes forgot to show a paint streak where I had previously rolled. Occasionally, the ball would randomly stop laying down paint at all. So I started to distrust Genie’s ability to recall what I had already seen with my own eyes.</p><p>Another Google-designed world, “Backyard Racetrack,” was a little more fun because there was an actual track to follow. My racing lines were awful — the input lag didn’t help — but I enjoyed trying to make the turns and stay on the road. Near the end of the experience, though, part of the track unexpectedly turned into grass, which ruined the immersion. And the wheel rims looked really janky.</p><p>I had a lot more fun pushing the limits of Project Genie to try and make 3D, AI-generated games featuring recognizable characters, like with my <em>Super Mario</em>, <em>Metroid Prime</em>, and <em>The Legend of Zelda</em>-themed worlds. While they made me laugh, the worlds don’t have scores or anything to strive for, so there’s nothing to do but walk or jump around. Even if there were specific things to do, the input lag made the worlds basically unplayable. (Again, this may be a Wi-Fi issue, but even when I was closer to my router, I still experienced lag.)</p><p>I wasn’t able to make everything I wanted. Project Genie wouldn’t generate a world that I prompted with the scenario of <em>Kingdom Hearts</em> — here was my prompt, if you’re curious:</p><div><blockquote><p>Environment</p><p>It’s a world filled with Disney characters with a steampunk vibe. Donald and Goofy are your sidekicks. Jack Skellington is present, as is Cloud Strife.</p><p>Character</p><p>You are a spunky, anime teenager with spiky brown hair wielding a blade that is like a key.</p></blockquote></div><p>When I removed the specific names of characters and wrote descriptions of them instead, Project Genie generated a thumbnail preview of the world featuring characters that were dead ringers for Sora (the series’ protagonist), Donald, Goofy, Jack Skellington, and Cloud. But when I tried to generate the actual experience, Project Genie blocked me.</p><p>I asked about why I was able to generate worlds with Nintendo characters. “Project Genie is an experimental research prototype designed to follow prompts a user provides,” Rivas says. “As with all experiments, we are monitoring closely and listening to user feedback.” Rivas also notes that the Genie 3 model was “trained primarily on publicly available data from the web.” (This probably partially explains why Link deployed his paraglider in my test, which surprised me. At a high level, the Genie model is constantly trying to predict the next frame, and I’m sure there are <em>many</em> videos of people jumping in <em>Breath of the Wild</em> and then gliding forward, which the model probably learned from.) Shortly before publishing this article, Project Genie stopped letting me generate worlds based on <em>Super Mario 64</em> due to “interests of third-party content providers.”</p><p>Assuming Google clamps down on the ability to generate interactive worlds based on known gaming franchises — I can’t imagine Nintendo will be happy with what I was able to generate! — Project Genie otherwise isn’t that great at the moment. The input lag and 60-second limit make them pretty poor interactive experiences. Occasionally, I couldn’t control my character at all, only the camera. After the weirdness with the paint stripes and the road turning into grass, I had a general feeling that I couldn’t trust the worlds to stay consistent from moment to moment.</p><p>Project Genie is better than <a href="https://www.theverge.com/ai-artificial-intelligence/675395/odyssey-ai-generated-interactive-video-holodeck">some AI-generated worlds I tried last year</a>, but it’s still much worse than an actual handcrafted video game or interactive experience. Fruchter described a potential future where the line blurs between different kinds of media thanks to technology like Genie, but I think it has a long way to go to get there.</p><p>Perhaps my standards are too high. Project Genie is an experimental research prototype, after all. And maybe I’ll feel differently after the technology improves down the line. But I can’t imagine that people will want to spend an extended period of time jumping into these types of AI-generated worlds anytime soon. With world models, I don’t think we have to worry about the genie being out of the bottle just yet.</p><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li id="follow-author-article_footer-dmcyOmF1dGhvclByb2ZpbGU6MTIz"><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span><span>Jay Peters</span></span></span></li><li></li><li></li><li></li><li></li><li></li></ul></div></div></div><br/><br/>https://www.theverge.com/news/869726/google-ai-project-genie-3-world-model-hands-on]]></content:encoded>
            <dc:creator>invalid@example.com (ResetEra_Newsbot</dc:creator>
        </item>
    </channel>
</rss>