<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>maGaming RSS Feed - theverge_com</title>
        <link>https://lukasz-gladek-av.github.io/custom-rss/theverge_com.xml</link>
        <description>A cleaned-up version of the original gaming feed for theverge_com</description>
        <lastBuildDate>Mon, 10 Feb 2025 22:30:52 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <item>
            <title><![CDATA[Roblox, Discord, OpenAI, and Google found new child safety group]]></title>
            <link>https://www.theverge.com/news/609367/roblox-discord-openai-google-roost-online-safety-tools</link>
            <guid>https://www.resetera.com/threads/roblox-discord-openai-and-google-found-new-child-safety-group.1105203/</guid>
            <content:encoded><![CDATA[https://www.theverge.com/news/609367/roblox-discord-openai-google-roost-online-safety-tools<br/><br/><div id="readability-page-1" class="page"><div id="zephr-anchor"><p>Google, OpenAI, Roblox, and Discord have formed a new non-profit organization to help improve child safety online. The <a href="https://www.prnewswire.com/news-releases/leading-technology-companies-and-foundations-back-new-initiative-to-provide-free-open-source-tools-for-a-safer-internet-in-the-ai-era-302371243.html">Robust Open Online Safety Tools (ROOST</a>) initiative aims to make core safety technologies more accessible for companies and provide free, open-source AI tools for identifying, reviewing, and reporting child sexual abuse material.</p><p>The initiative was partially motivated by <a href="https://www.theverge.com/2024/4/23/24138356/ai-companies-csam-thorn-training-data">changes that generative AI advancements</a> have made to online environments and aims to address “a critical need to accelerate innovation in online child safety,” according to founding ROOST partner and former Google CEO Eric Schmidt. Details about the CSAM detection tools are slim beyond that they will utilize large language AI models and “unify” existing options for dealing with the content.</p><p>“Starting with a platform focused on child protection, ROOST’s collaborative, open-source approach will foster innovation and make essential infrastructure more transparent, accessible, and inclusive, with the goal of creating a safer internet for everyone,” said Schmidt.</p><div><p>The <a href="https://roost.tools/">ROOST</a> announcement comes amid a <a href="https://www.theverge.com/24205393/kids-online-safety-act-minors-age-verification-kosa">huge regulatory battle regarding child safety</a> on social media and online platforms, with companies seeking to appease lawmakers with self-regulation methods.</p></div><div><p>The <a href="https://www.missingkids.org/cybertiplinedata">National Center for Missing and Exploited Children</a> (NCMEC) reports that suspected child exploitation increased by 12 percent between 2022 and 2023. As of 2020, <a href="https://www.theverge.com/2020/7/21/21333431/roblox-over-half-of-us-kids-playing-virtual-parties-fortnite">over half of US children were on Roblox</a>, and the company has been <a href="https://www.theverge.com/2024/10/4/24262033/roblox-the-bear-cave-child-abuse">repeatedly criticized</a> for <a href="https://www.theverge.com/2024/10/23/24277992/roblox-pre-teen-children-parent-accounts-default-settings">failing to tackle child sexual exploitation</a> and <a href="https://www.theverge.com/2024/11/21/24296652/new-york-childrens-online-safety-act-gounardes-privacy">exposure to inappropriate content</a> on its platform. Roblox and Discord were also <a href="https://www.theverge.com/2022/10/6/23390796/roblox-discord-facebook-snapchat-social-media-lawsuits-addiction-child-abuse">singled out in a social media lawsuit filed in 2022</a> that alleged the platforms failed to stop adults from messaging children without supervision.</p></div><p>Founding members of ROOST are variously providing funding and offering their tools or expertise to the project. ROOST says it’s partnering with leading AI foundation model developers to build a “community of practice” for content safeguards, which will include providing vetted AI training datasets and identifying gaps in safety.</p><p>The initiative says it will be making “tools that already exist” more accessible, effectively combining various detection and reporting tech from its member organizations into a unified solution that’s easier for other companies to implement. Naren Koneru, Roblox’s vice president of engineering, trust, and safety, <a href="https://www.fastcompany.com/91275256/roblox-joins-27-million-industry-nonprofit-to-support-online-safety">told <em>Fast Company</em></a> that ROOST may host AI moderation systems that companies can integrate through API calls. There’s some ambiguity about what ROOST’s AI moderation tools will include, however.</p><p>For example, Discord says its contributions will build on the <a href="https://www.theverge.com/2023/11/7/23950604/lantern-program-csam-child-exploitation-google-meta-discord-privacy">Lantern cross-platform information-sharing project</a> it joined in 2023 alongside Meta and Google. It could also include <a href="https://github.com/Roblox/voice-safety-classifier">an updated version of Roblox’s AI model</a> for detecting profanity, racism, bullying, sexting, and other inappropriate content in audio clips, which the company is planning to open-source this year. It’s unclear precisely how the tools will intersect with existing first-line CSAM detection systems like <a href="https://www.microsoft.com/en-us/photodna">Microsoft’s PhotoDNA image analysis tool</a>.</p><p>Alongside <a href="https://discord.com/safety/safer-internet-day-2025">its participation in ROOST</a>, Discord has released <a href="https://www.theverge.com/news/609310/discord-ignore-mute-users-feature-block">a new “Ignore” feature</a> that allows users to hide messages and notifications they receive without notifying the people they have muted. “At Discord, we believe that safety is a common good,” Discord’s Chief Legal Officer Clint Smith said in the ROOST announcement. “We’re committed to making the entire internet - not just Discord - a better and safer place, especially for young people.” </p><p>ROOST has raised more than $27 million to support its first four years of operations, backed by philanthropic organizations including the McGovern Foundation, Future of Online Trust and Safety Fund, Knight Foundation, and the AI Collaborative. The ROOST organization will also be supported by experts in child safety, artificial intelligence, open-source technology, and “countering violent extremism” according to the press release.</p></div></div>]]></content:encoded>
        </item>
    </channel>
</rss>