<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>maGaming RSS Feed - wccftech_com</title>
        <link>https://lukasz-gladek-av.github.io/custom-rss/wccftech_com.xml</link>
        <description>A cleaned-up version of the original gaming feed for wccftech_com</description>
        <lastBuildDate>Wed, 08 Jan 2025 02:42:11 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <item>
            <title><![CDATA[NVIDIA RTX Kit Shows How Neural Rendering Will Power the Next Visual Leap in Gaming]]></title>
            <link>https://wccftech.com/nvidia-rtx-kit-shows-how-neural-rendering-will-power-the-next-visual-leap-in-gaming/</link>
            <guid>https://www.resetera.com/threads/nvidia-rtx-kit-shows-how-neural-rendering-will-power-the-next-visual-leap-in-gaming.1076619/</guid>
            <content:encoded><![CDATA[https://wccftech.com/nvidia-rtx-kit-shows-how-neural-rendering-will-power-the-next-visual-leap-in-gaming/<br/><br/><div id="readability-page-1" class="page"><div>

			

			
			
			
			<p>Alongside the new <a href="https://wccftech.com/nvidia-geforce-rtx-5090-32-gb-gpu-1999-usd-2x-performance-of-4090/" target="_blank" rel="noopener">GeForce RTX 50 Series GPUs</a>, CES 2025 also marked the debut of the <a href="https://developer.nvidia.com/rtx-kit/" target="_blank" rel="noopener">NVIDIA RTX Kit</a>, a new suite of neural rendering technologies that promises to empower game developers to deliver the next visual leap in graphics. The NVIDIA RTX Kit suite has vast applications, from accelerating ray tracing with AI to portraying much more realistic digital humans to rendering scenes that feature massive amounts of geometry.</p>
<p>Let's begin with what's arguably going to be the biggest innovation. With the Blackwell architecture, NVIDIA is introducing the so-called RTX Neural Shaders. These are small neural networks that are meant to be injected into programmable shaders for various beneficial effects. With the upcoming RTX Neural Shaders SDK, game developers can train their game data and shader code on an RTX AI PC accelerated with NVIDIA Tensor Cores. During the training phase, the neural game data is compared to the output of the traditional data and refined over multiple cycles.</p>
<p>There are currently three main applications for RTX Neural Shaders, all of which we&nbsp;<span>previously covered from NVIDIA's research papers: RTX <a href="https://wccftech.com/nvidia-neural-compression-technique-unlocks-16x-texture-detail/" target="_blank" rel="noopener">Neural Texture Compression</a>, RTX <a href="https://wccftech.com/nvidia-real-time-neural-materials-models-up-to-24x-shading-speedup/" target="_blank" rel="noopener">Neural Materials</a>, and RTX <a href="https://wccftech.com/neural-radiance-cache-technique-aims-to-make-path-tracing-faster-on-nvidia-gpus-thanks-to-tensor-cores-and-ai/" target="_blank" rel="noopener">Neural Radiance Cache</a></span>. RTX Neural Texture Compression is invaluable for easily compressing thousands of textures in less than a minute while also saving up to 7x more VRAM compared to traditional block-compressed textures, with no purported downside to quality. In the new tech demo, RTX NTC textures only occupy 80MB, whereas regular block-compressed textures require 520MB VRAM.</p>

<figure><a href="https://cdn.wccftech.com/wp-content/uploads/2025/01/RTX-NTC-scaled.jpg"></a></figure>

<p>RTX Neural Materials uses AI to compress complex shader code typically reserved for offline materials, delivering up to five times quicker material processing and enabling higher quality assets to be available in games.</p>

<figure><a href="https://cdn.wccftech.com/wp-content/uploads/2025/01/RTX-Neural-Materials-scaled.jpg"></a></figure>

<p>Lastly, AI is used in RTX Neural Radiance Cache to infer an infinite number of bounces after the initial one to two bounces, thus improving multi-bounce indirect lighting and performance. NRC has already been <a href="https://wccftech.com/nvidia-rtxgi-2-0-available-next-frontier-ray-traced-visuals-neural-radiance-cache-spatial-hash-radiance-cache-dynamic-diffuse-global-illumination/" target="_blank" rel="noopener">available for a while</a> as part of the RTX GI SDK and will soon be introduced to RTX Remix and Portal with RTX.</p>

<figure><a href="https://cdn.wccftech.com/wp-content/uploads/2025/01/RTX-Neural-Radiance-Cache-scaled.jpg"></a></figure>

<p>The RTX Neural Shaders and RTX Neural Texture Compression SDKs will be added to the NVIDIA RTX Kit later this month. Microsoft also <a href="https://devblogs.microsoft.com/directx/enabling-neural-rendering-in-directx-cooperative-vector-support-coming-soon/" target="_blank" rel="noopener">announced</a> today that DirectX will soon add support for Cooperative Vectors, providing accelerated performance for GeForce RTX GPUs when using RTX Neural Shaders. Bryan Langley, partner group program manager of Silicon, Media, and Graphics at Microsoft, stated:</p>
<p><em>Microsoft is excited to partner with NVIDIA to catalyze this next generation of graphics programming by bringing industry-wide support for neural shading technology. DirectX will soon support Cooperative Vectors, which will unlock the power of Tensor Cores on NVIDIA GeForce RTX hardware and enable game developers to fully accelerate neural shaders on Windows.</em></p>

<figure><a href="https://cdn.wccftech.com/wp-content/uploads/2025/01/RTX-Mega-Geometry-Off-scaled.jpg"></a></figure>

<p>The NVIDIA RTX Kit also includes RTX Mega Geometry, which will <a href="https://wccftech.com/doom-the-dark-ages-features-dlss-4-path-tracing-at-launch-indiana-jones-alan-wake-2-updated-with-new-rtx-technologies/" target="_blank" rel="noopener">debut in Remedy's Alan Wake 2</a> with a free update later this year. The CES 2025 demo video provided a preview of the technology, which aims to improve the ray tracing load in scenes with vast amounts of geometry, like in games powered by Unreal Engine 5's Nanite. According to NVIDIA, RTX Mega Geometry accelerates BVH building, enabling ray tracing of up to a hundred times more triangles than the current standard. It will be available later this month in the RTX Kit, and soon through the NVIDIA RTX Unreal Engine branch.</p>

<figure><a href="https://cdn.wccftech.com/wp-content/uploads/2025/01/RTX-Mega-Geometry-On-scaled.jpg"></a></figure>

<p>RTX Neural Faces is the tool in the NVIDIA RTX Kit that takes a regular rasterized face with 3D pose data as input and infers a more natural face through a real-time gen AI model. The generated face is trained from thousands of offline generated images of that face at every angle, under different lighting, emotion, and occlusion conditions. The training pipeline can use real photographs or AI-generated images. The trained model is then optimized using NVIDIA TensorRT to infer the face in real-time.</p>

<figure><a href="https://cdn.wccftech.com/wp-content/uploads/2025/01/Standard-Face-scaled.jpg"></a></figure>

<p>This is paired with the RTX Character Rendering SDK for hair and skin. With the new GeForce RTX 50 Series GPUs, NVIDIA added Linear-Swept Spheres (LSS), a GPU-accelerated primitive that reduces the amount of geometry required to render strands of hair. LSS uses spheres instead of triangles to match hair shapes more accurately. LSS enables ray-traced hair to be rendered with better performance and a smaller memory footprint. RTX Skin and Hair algorithms using the RTX Character Rendering SDK, which will be available later this month, just like the NVIDIA RTX Kit. The Hair algorithm will debut in Indiana Jones and the Great Circle with a free update coming soon. The Skin algorithm will be available through RTX Remix, too.</p>

<figure><a href="https://cdn.wccftech.com/wp-content/uploads/2025/01/RTX-Neural-Face-scaled.jpg"></a></figure>

<p>Last but not least, NVIDIA also promised a big update to its Audio2Face technology. Truth be told, we weren't exceedingly impressed with its implementation in GSC Game World's <a href="https://wccftech.com/review/stalker-2-heart-of-chornobyl-the-anomaly-never-changes/" target="_blank" rel="noopener">STALKER 2</a> game; the AI didn't do a great job of delivering decent facial animations based on audio inputs. The brief new demo video looks a lot more expressive, though. According to NVIDIA, a new Audio2Face real-time diffusion-based architecture has been implemented to deliver more accurate and detailed lip synchronization, vivid emotions, and natural non-verbal responses.</p>
<p><iframe loading="lazy" title="NVIDIA ACE | New Audio-driven AI Facial Animation Features Coming to NVIDIA Audio2Face" width="500" height="281" src="https://www.youtube.com/embed/dm8-gNin76c?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>

			
		</div></div>]]></content:encoded>
        </item>
    </channel>
</rss>