<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>maGaming RSS Feed - arstechnica_com</title>
        <link>https://lukasz-gladek-av.github.io/custom-rss/arstechnica_com.xml</link>
        <description>A cleaned-up version of the original gaming feed for arstechnica_com</description>
        <lastBuildDate>Wed, 05 Mar 2025 23:07:15 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <item>
            <title><![CDATA[AMD Radeon RX 9070 and 9070 XT review: RDNA 4 fixes a lot of AMD’s problems]]></title>
            <link>https://arstechnica.com/gadgets/2025/03/amd-radeon-rx-9070-and-9070-xt-review-rdna-4-fixes-a-lot-of-amds-problems/</link>
            <guid>https://www.resetera.com/threads/amd-radeon-rx-9070-and-9070-xt-review-rdna-4-fixes-a-lot-of-amd%E2%80%99s-problems.1126368/</guid>
            <content:encoded><![CDATA[https://arstechnica.com/gadgets/2025/03/amd-radeon-rx-9070-and-9070-xt-review-rdna-4-fixes-a-lot-of-amds-problems/<br/><br/><div id="readability-page-1" class="page"><div id="app">
    <p><a href="#main">
  Skip to content
</a></p>



<main id="main">
            <article data-id="2078344">
  
  <header>
  <div>
    

    

    <p>
      For $549 and $599, AMD comes close to knocking out Nvidia's GeForce RTX 5070.
    </p>

    

    <div id="caption-2079857">
    
    <p>
      AMD's Radeon RX 9070 and 9070 XT are its first cards based on the RDNA 4 GPU architecture.

              <span>
          Credit:

          
          Andrew Cunningham

                  </span>
          </p>
  </div>

    <div>
    
    <p>
      AMD's Radeon RX 9070 and 9070 XT are its first cards based on the RDNA 4 GPU architecture.

              <span>
          Credit:

          
          Andrew Cunningham

                  </span>
          </p>
  </div>
  </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>AMD is a company that knows a thing or two about capitalizing on a competitor's weaknesses. The company got through its <a href="https://arstechnica.com/information-technology/2013/04/amd-on-ropes-from-the-top-of-the-mountain-to-the-deepest-valleys/">early-2010s nadir</a> partially because its Ryzen CPUs struck just as Intel's current manufacturing woes began to set in, first with <a href="https://arstechnica.com/gadgets/2017/03/amd-ryzen-review/">somewhat-worse CPUs that were great value for the money</a>&nbsp;and later with CPUs that were <a href="https://arstechnica.com/gadgets/2020/11/hands-on-zen-3-testing-with-amds-ryzen-9-5900x-and-5950x/">better than anything Intel could offer</a>.</p>
<p>Nvidia's untrammeled dominance of the consumer graphics card market should also be an opportunity for AMD. Nvidia's GeForce RTX 50-series graphics cards have given buyers very little to get excited about, with an unreachably expensive high-end 5090 refresh and modest-at-best gains from 5080 and 5070-series cards that are <em>also</em> pretty expensive by historical standards, when you can buy them at all. Tech YouTubers—both the people making the videos and the people leaving comments underneath them—have been almost uniformly unkind to the 50 series, hinting at consumer frustrations and pent-up demand for competitive products from other companies.</p>
<p>Enter AMD's Radeon RX 9070 XT and RX 9070 graphics cards. These are aimed right at the middle of the current GPU market at the intersection of high sales volume and decent profit margins. They promise good 1440p and entry-level 4K gaming performance and improved power efficiency compared to previous-generation cards, with fixes for long-time shortcomings (ray-tracing performance, video encoding, and upscaling quality) that should, in theory, make them more tempting for people looking to ditch Nvidia.</p>
<p><span>Table of Contents</span>

  
</p>

<h2>RX 9070 and 9070 XT specs and speeds</h2>
<div><table>
<tbody>
<tr>
<th></th>
<th>RX 9070 XT</th>
<th>RX 9070</th>
<th>RX 7900 XTX</th>
<th>RX 7900 XT</th>
<th>RX 7900 GRE</th>
<th>RX 7800 XT</th>
</tr>
<tr>
<th>Compute units (Stream processors)</th>
<td>64 RDNA4 (4,096)</td>
<td>56 RDNA4 (3,584)</td>
<td>96 RDNA3 (6,144)</td>
<td>84 RDNA3 (5,376)</td>
<td>80 RDNA3 (5,120)</td>
<td>60 RDNA3 (3,840)</td>
</tr>
<tr>
<th>Boost Clock</th>
<td>2,970 MHz</td>
<td>2,520 MHz</td>
<td>2,498 MHz</td>
<td>2,400 MHz</td>
<td>2,245 MHz</td>
<td>2,430 MHz</td>
</tr>
<tr>
<th>Memory Bus Width</th>
<td>256-bit</td>
<td>256-bit</td>
<td>384-bit</td>
<td>320-bit</td>
<td>256-bit</td>
<td>256-bit</td>
</tr>
<tr>
<th>Memory Bandwidth</th>
<td>650GB/s</td>
<td>650GB/s</td>
<td>960GB/s</td>
<td>800GB/s</td>
<td>576GB/s</td>
<td>624GB/s</td>
</tr>
<tr>
<th>Memory size</th>
<td>16GB GDDR6</td>
<td>16GB GDDR6</td>
<td>24GB GDDR6</td>
<td>20GB GDDR6</td>
<td>16GB GDDR6</td>
<td>16GB GDDR6</td>
</tr>
<tr>
<th>Total board power (TBP)</th>
<td>304 W</td>
<td>220 W</td>
<td>355 W</td>
<td>315 W</td>
<td>260 W</td>
<td>263 W</td>
</tr>
</tbody>
</table></div>
<p>AMD's high-level performance promise for the RDNA 4 architecture revolves around big increases in performance per compute unit (CU). An RDNA 4 CU, AMD says, is nearly twice as fast in rasterized performance as RDNA 2 (that is, rendering without ray-tracing effects enabled) and nearly 2.5 times as fast as RDNA 2 in games with ray-tracing effects enabled. Performance for at least some machine learning workloads also goes way up—twice as fast as RDNA 3 and four times as fast as RDNA 2.</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>We'll see this in more detail when we start comparing performance, but AMD seems to have accomplished this goal. Despite having 64 or 56 compute units (for the 9070 XT and 9070, respectively), the cards' performance often competes with AMD's last-generation flagships, the RX 7900 XTX and 7900 XT. Those cards came with 96 and 84 compute units, respectively. The 9070 cards are specced a lot more like last generation's RX 7800 XT—including the 16GB of GDDR6 on a 256-bit memory bus, as AMD still isn't using GDDR6X or GDDR7—but they're much faster than the 7800 XT was.</p>

<div>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="arrow-blocks-right_svg__a"><path fill="none" d="M0 0h40v40H0z"></path></clipPath></defs><g fill="currentColor" clip-path="url(#arrow-blocks-right_svg__a)"><path d="M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z"></path></g></svg>

    <p><span>AMD has dramatically increased the performance-per-compute unit for RDNA 4.</span>
                    <span>
                      AMD
                  </span>
          </p>
  </div>

<p>The 9070 series also uses a new 4 nm manufacturing process from TSMC, an upgrade from the 7000 series' 5 nm process (and the 6 nm process used for the separate memory controller dies in higher-end RX 7000-series models that used chiplets). AMD's GPUs are normally a bit less efficient than Nvidia's, but the architectural improvements and the new manufacturing process allow AMD to do some important catch-up.</p>
<p>Both of the 9070 models we tested were ASRock Steel Legend models, and the 9070 and 9070 XT had identical designs—we'll probably see a lot of this from AMD's partners since the GPU dies and the 16GB RAM allotments are the same for both models. Both use two 8-pin power connectors; AMD says partners are free to use the 12-pin power connector if they want, but given Nvidia's ongoing issues with it, most cards will likely stick with the reliable 8-pin connectors.</p>


<p>AMD doesn't appear to be making and selling reference designs for the 9070 series the way it did for some RX 7000 and 6000-series GPUs or the way Nvidia does with its Founders Edition cards. From what we've seen, 2 or 2.5-slot, triple-fan designs will be the norm, the way they are for most midrange GPUs these days.</p>
<h3>Testbed notes</h3>

<p>We used the same GPU testbed for the Radeon RX 9070 series as we have for our GeForce RTX 50-series reviews.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>An AMD Ryzen 7 9800X3D ensures that our graphics cards will be CPU-limited as little as possible. An ample 1050 W power supply, 32GB of DDR5-6000, and an AMD X670E motherboard with the latest BIOS installed round out the hardware. On the software side, we use an up-to-date installation of Windows 11 24H2 and recent GPU drivers for older cards, ensuring that our tests reflect whatever optimizations Microsoft, AMD, Nvidia, and game developers have made since the last generation of GPUs launched.</p>
<p>We have numbers for all of Nvidia's RTX 50-series GPUs so far, plus most of the 40-series cards, most of AMD's RX 7000-series cards, and a handful of older GPUs from the RTX 30-series and RX 6000 series. We'll focus on comparing the 9070 XT and 9070 to other 1440p-to-4K graphics cards since those are the resolutions AMD is aiming at.</p>

<h2>Performance</h2>
<p>At $549 and $599, the 9070 series is priced to match Nvidia's $549 RTX 5070 and undercut the $749 RTX 5070 Ti. So we'll focus on comparing the 9070 series to those cards, plus the top tier of GPUs from the outgoing RX 7000-series.</p>
<div>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="arrow-blocks-right_svg__a"><path fill="none" d="M0 0h40v40H0z"></path></clipPath></defs><g fill="currentColor" clip-path="url(#arrow-blocks-right_svg__a)"><path d="M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z"></path></g></svg>

    <p><span>Some 4K rasterized benchmarks.</span>
                </p>
  </div>

<p>Starting at the top with rasterized benchmarks with no ray-tracing effects, the 9070 XT does a good job of standing up to Nvidia's RTX 5070 Ti, coming within a few frames per second of its performance in all the games we tested (and scoring very similarly in the 3DMark Time Spy Extreme benchmark).</p>


<p>Both cards are considerably faster than the RTX 5070—between 15 and 28 percent for the 9070 XT and between 5 and 13 percent for the regular 9070 (our 5070 scored weirdly low in <em>Horizon Zero Dawn Remastered</em>, so we'd treat those numbers as outliers for now). Both 9070 cards also stack up well next to the RX 7000 series here—the 9070 can usually just about match the performance of the 7900 XT, and the 9070 XT usually beats it by a little. Both cards thoroughly outrun the old RX 7900 GRE, which was AMD's $549 GPU offering just a year ago.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>The 7900 XT does have 20GB of RAM instead of 16GB, which might help its performance in some edge cases. But 16GB is still perfectly generous for a 1440p-to-4K graphics card—the 5070 only offers 12GB, which could end up limiting its performance in some games as RAM requirements continue to rise.</p>
<h3>On ray-tracing improvements</h3>
<p>Nvidia got a jump on AMD when it introduced hardware-accelerated ray-tracing in the RTX 20-series in 2018. And while these effects were only supported in a few games at the time, many modern games offer at least some kind of ray-traced lighting effects.</p>
<p>AMD caught up a little when it began shipping its own ray-tracing support in the RDNA2 architecture in late 2020, but the issue since then has always been that AMD cards have taken a larger performance hit than GeForce GPUs when these effects are turned on. RDNA3 promised improvements, but our tests still generally showed the same deficit as before.</p>
<p>So we're looking for two things with RDNA4's ray-tracing performance. First, we want the numbers to be higher than they were for comparably priced RX 7000-series GPUs, the same thing we look for in non-ray-traced (or rasterized) rendering performance. Second, we want the size of the performance hit to go down. To pick an example: the RX 7900 GRE could compete with Nvidia's RTX 4070 Ti Super in games without ray tracing, but it was closer to a non-Super RTX 4070 in ray-traced games. It has helped keep AMD's cards from being across-the-board competitive with Nvidia's—is that any different now?</p>
<div>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="arrow-blocks-right_svg__a"><path fill="none" d="M0 0h40v40H0z"></path></clipPath></defs><g fill="currentColor" clip-path="url(#arrow-blocks-right_svg__a)"><path d="M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z"></path></g></svg>

    <p><span>Benchmarks for games with ray-tracing effects enabled. Both AMD cards generally keep pace with the 5070 in these tests thanks to RDNA 4's improvements.</span>
                </p>
  </div>

<p>The picture our tests paint is mixed but tentatively positive. The 9070 series and RDNA4 post solid improvements in the <em>Cyberpunk 2077&nbsp;</em>benchmarks, substantially closing the performance gap with Nvidia. In games where AMD's cards performed well enough before—here represented by&nbsp;<em>Returnal</em>—performance goes up, but roughly proportionately with rasterized performance. And both 9070 cards still punch below their weight in&nbsp;<em>Black Myth: Wukong</em>, falling substantially behind the 5070 under the punishing Cinematic graphics preset.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>So the benefits you see, as with any GPU update, will depend a bit on the game you're playing. There's also a possibility that game optimizations and driver updates made with RDNA4 in mind could boost performance further. We can't say that AMD has caught all the way up to Nvidia here—the 9070 and 9070 XT are both closer to the GeForce RTX 5070 than the 5070 Ti, despite keeping it closer to the 5070 Ti in rasterized tests—but there <em>is</em> real, measurable improvement here, which is what we were looking for.</p>

<h3>Power usage</h3>


<p>The 9070 series' performance increases are particularly impressive when you look at the power-consumption numbers. The 9070 comes close to the 7900 XT's performance but uses 90 W less power under load. It beats the RTX 5070 most of the time but uses around 30 W less power.</p>
<p>The 9070 XT is a little less impressive on this front—AMD has set clock speeds pretty high, and this can increase power use disproportionately. The 9070 XT is usually 10 or 15 percent faster than the 9070 but uses 38 percent more power. The XT's power consumption is similar to the RTX 5070 Ti's (a GPU it often matches) and the 7900 XT's (a GPU it always beats), so it's not <em>too</em> egregious, but it's not as standout as the 9070's.</p>
<p>AMD gives 9070 owners a couple of new toggles for power limits, though, which we'll talk about in the next section.</p>
<h3>Experimenting with “Total Board Power”</h3>
<p>We don't normally dabble much with overclocking when we review CPUs or GPUs—we're happy to leave that to folks at other outlets. But when we review CPUs, we do usually test them with multiple power limits in place. Playing with power limits is easier (and occasionally safer) than actually overclocking, and it often comes with large gains to either performance (a chip that performs much better when given more power to work with) or efficiency (a chip that can run at nearly full speed without using as much power).</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>Initially, I experimented with the RX 9070's power limits by accident. AMD sent me one version of the 9070 but exchanged it because of a minor problem the OEM identified with some units early in the production run. I had, of course, already run most of our tests on it, but that's the way these things go sometimes.</p>
<div>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="arrow-blocks-right_svg__a"><path fill="none" d="M0 0h40v40H0z"></path></clipPath></defs><g fill="currentColor" clip-path="url(#arrow-blocks-right_svg__a)"><path d="M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z"></path></g></svg>

    <p><span>By bumping the regular RX 9070's TBP up just a bit, you can nudge it closer to 9070 XT-level performance.</span>
                </p>
  </div>

<p>The replacement RX 9070 card, an ASRock Steel Legend model, was performing significantly better in our tests, sometimes nearly closing the gap between the 9070 and the XT. It wasn't until I tested power consumption that I discovered the explanation—by default, it was using a 245 W power limit rather than the AMD-defined 220 W limit. Usually, these kinds of factory tweaks don't make much of a difference, but for the 9070, this power bump gave it a nice performance boost while still keeping it close to the 250 W power limit of the GeForce RTX 5070.</p>
<p>The 90-series cards we tested both add some power presets to AMD's Adrenalin app in the Performance tab under Tuning. These replace and/or complement some of the automated overclocking and undervolting buttons that exist here for older Radeon cards. Clicking Favor Efficiency or Favor Performance can ratchet the card's Total Board Power (TBP) up or down, limiting performance so that the card runs cooler and quieter or allowing the card to consume more power so it can run a bit faster.</p>
<figure>
    
          <figcaption>
        <div>
    
    <p>
      The 9070 cards get slightly different performance tuning options in the Adrenalin software. These buttons mostly change the card's Total Board Power (TBP), making it simple to either improve efficiency or boost performance a bit.

              <span>
          Credit:

          
          Andrew Cunningham

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>For this particular ASRock 9070 card, the default TBP is set to 245 W. Selecting "Favor Efficiency" sets it to the default 220 W. You can double-check these values using an app like <a href="https://www.hwinfo.com/">HWInfo</a>, which displays both the current TBP and the maximum TBP in its Sensors Status window. Clicking the Custom button in the Adrenalin software gives you access to a Power Tuning slider, which for our card allowed us to ratchet the TBP up by up to 10 percent or down by as much as 30 percent.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>This is all the firsthand testing we did with the power limits of the 9070 series, though I would assume that adding a bit more power also adds more overclocking headroom (bumping up the power limits is common for GPU overclockers no matter who makes your card). AMD says that some of its partners will ship 9070 XT models set to a roughly 340 W power limit out of the box but acknowledges that "you start seeing diminishing returns as you approach the top of that [power efficiency] curve."</p>
<p>But it's worth noting that the driver has another automated set-it-and-forget-it power setting you can easily use to find your preferred balance of performance and power efficiency.</p>

<h3>A quick look at FSR4 performance</h3>
<figure>
    
          <figcaption>
        <div>
    
    <p>
      There's a toggle in the driver for enabling FSR 4 in FSR 3.1-supporting games.

              <span>
          Credit:

          
          Andrew Cunningham

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>One of AMD's headlining improvements to the RX 90-series is the introduction of FSR 4, a new version of its FidelityFX Super Resolution upscaling algorithm. Like Nvidia's DLSS and Intel's XeSS, FSR 4 can take advantage of RDNA 4's machine learning processing power to do hardware-backed upscaling instead of taking a hardware-agnostic approach as the older FSR versions did. AMD says this will improve upscaling quality, but it also means FSR4 will only work on RDNA 4 GPUs.</p>
<p>The good news is that FSR 3.1 and FSR 4 are forward- and backward-compatible. Games that have already added FSR 3.1 support can automatically take advantage of FSR 4, and games that support FSR 4 on the 90-series can just run FSR 3.1 on older and non-AMD GPUs.</p>
<figure>
    
          <figcaption>
        <div>
    
    <p>
      FSR 4 comes with a small performance hit compared to FSR 3.1 at the same settings, but better overall quality can let you drop to a faster preset like Balanced or Performance and end up with more frames-per-second overall.

              <span>
          Credit:

          
          Andrew Cunningham

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>The only game in our current test suite to be compatible with FSR 4 is&nbsp;<em>Horizon Zero Dawn Remastered</em>, and we tested its performance using both FSR 3.1 and FSR 4. In general, we found that FSR 4 improved visual quality at the cost of just a few frames per second when run at the same settings—not unlike using Nvidia's recently released "transformer model" for DLSS upscaling.</p>
<p>Many games will let you choose which version of FSR you want to use. But for FSR 3.1 games that don't have a built-in FSR 4 option, there's a toggle in AMD's Adrenalin driver you can hit to switch to the better upscaling algorithm.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>Even if they come with a performance hit, new upscaling algorithms <em>can</em> still improve performance by making the lower-resolution presets look better. We run all of our testing in "Quality" mode, which generally renders at two-thirds of native resolution and scales up. But if FSR 4 running in Balanced or Performance mode looks the same to your eyes as FSR 3.1 running in Quality mode, you can still end up with a net performance improvement in the end.</p>
<h3>RX 9070 or 9070 XT?</h3>
<p>Just $50 separates the advertised price of the 9070 from that of the 9070 XT, something both Nvidia and AMD have done in the past that I find a bit annoying. If you have $549 to spend on a graphics card, you can almost certainly scrape together $599 for a graphics card. All else being equal, I'd tell most people trying to choose one of these to just spring for the 9070 XT.</p>
<p>That said, availability and retail pricing for these might be all over the place. If your choices are a regular RX 9070 or nothing, or an RX 9070 at $549 and an RX 9070 XT at any price higher than $599, I would just grab a 9070 and not sweat it too much. The two cards aren't&nbsp;<em>that</em> far apart in performance, especially if you bump the 9070's TBP up a little bit, and games that are playable on one will be playable at similar settings on the other.</p>

<h2>Pretty close to great</h2>
<figure>
    
          <figcaption>
        <div>
    
    <p>
      If you're building a 1440p or 4K gaming box, the 9070 series might be the ones to beat right now.

              <span>
          Credit:

          
          Andrew Cunningham

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>We've got plenty of objective data in here, so I don't mind saying that I came into this review kind of&nbsp;<em>wanting</em> to like the 9070 and 9070 XT. Nvidia's 50-series cards have mostly upheld the status quo, and for the last couple of years, the status quo has been sustained high prices and very modest generational upgrades. And who doesn't like an underdog story?</p>
<p>I think our test results mostly justify my priors. The RX 9070 and 9070 XT are very competitive graphics cards, helped along by a particularly mediocre RTX 5070 refresh from Nvidia. In non-ray-traced games, both cards wipe the floor with the 5070 and come close to competing with the $749 RTX 5070 Ti. In games and synthetic benchmarks with ray-tracing effects on, both cards can usually match or slightly beat the similarly priced 5070, partially (if not entirely) addressing AMD's longstanding performance deficit here. Neither card comes close to the 5070 Ti in these games, but they're also not priced like a 5070 Ti.</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<p>Just as impressively, the Radeon cards compete with the GeForce cards while consuming similar amounts of power. At stock settings, the RX 9070 uses roughly the same amount of power under load as a 4070 Super but with better performance. The 9070 XT uses about as much power as a 5070 Ti, with similar performance before you turn ray-tracing on. Power efficiency was a small but consistent drawback for the RX 7000 series compared to GeForce cards, and the 9070 cards mostly erase that disadvantage. AMD is also less stingy with the RAM, giving you 16GB for the price Nvidia charges for 12GB.</p>
<p>Some of the old caveats still apply. Radeons take a bigger performance hit, proportionally, than GeForce cards. DLSS already looks pretty good and is widely supported, while FSR 3.1/FSR 4 adoption is still relatively low. Nvidia has a nearly monopolistic grip on the dedicated GPU market, which means many apps, AI workloads, and games support its GPUs best/first/exclusively. AMD is always playing catch-up to Nvidia in some respect, and Nvidia keeps progressing quickly enough that it feels like AMD never quite has the opportunity to close the gap.</p>
<p>AMD also doesn't have an answer for DLSS Multi-Frame Generation. The benefits of that technology are fairly narrow, and you already get <em>most</em> of those benefits with single-frame generation. But it's still a thing that <a href="https://sega.fandom.com/wiki/Sega_does_what_Nintendon%27t">Nvidia does that AMDon't</a>.</p>
<p>Overall, the RX 9070 cards are both awfully tempting competitors to the GeForce RTX 5070—and occasionally even the 5070 Ti. They're great at 1440p and decent at 4K. Sure, I'd like to see them priced another $50 or $100 cheaper to well and truly undercut the 5070 and bring 1440p-to-4K performance t0 a sub-$500 graphics card. It would be nice to see AMD undercut Nvidia's GPUs as ruthlessly as it undercut Intel's CPUs nearly a decade ago. But these RDNA4 GPUs have way fewer downsides than previous-generation cards, and they come at a moment of relative weakness for Nvidia. We'll see if the sales follow.</p>
<h3>The good</h3>
<ul>
<li>Great 1440p performance and solid 4K performance</li>
<li>16GB of RAM</li>
<li>Decisively beats Nvidia's RTX 5070, including in most ray-traced games</li>
<li>RX 9070 XT is competitive with RTX 5070 Ti in non-ray-traced games for less money</li>
<li>Both cards match or beat the RX 7900 XT, AMD's second-fastest card from the last generation</li>
<li>Decent power efficiency for the 9070 XT and great power efficiency for the 9070</li>
<li>Automated options for tuning overall power use to prioritize either efficiency or performance</li>
<li>Reliable 8-pin power connectors available in many cards</li>
</ul>
<h3>The bad</h3>
<ul>
<li>Nvidia's ray-tracing performance is still usually better</li>
<li>At $549 and $599, pricing matches but doesn't undercut the RTX 5070</li>
<li>FSR 4 isn't as widely supported as DLSS and may not be for a while</li>
</ul>
<h4>The ugly</h4>
<ul>
<li>Playing the "can you actually buy these for AMD's advertised prices" game</li>
</ul>


          
                  </div>

                  
          






  <div>
    

    <p>
      Andrew is a Senior Technology Reporter at Ars Technica, with a focus on consumer tech including computer hardware and in-depth reviews of operating systems like Windows and macOS. Andrew lives in Philadelphia and co-hosts a weekly book podcast called <a href="https://overduepodcast.com/">Overdue</a>.
    </p>
  </div>


  <p>
    <a href="https://arstechnica.com/gadgets/2025/03/amd-radeon-rx-9070-and-9070-xt-review-rdna-4-fixes-a-lot-of-amds-problems/#comments" title="59 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    59 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  


  

  </main>





  </div></div>]]></content:encoded>
        </item>
    </channel>
</rss>