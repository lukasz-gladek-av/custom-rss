<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>maGaming RSS Feed - arstechnica_com</title>
        <link>https://lukasz-gladek-av.github.io/custom-rss/arstechnica_com.xml</link>
        <description>A cleaned-up version of the original gaming feed for arstechnica_com</description>
        <lastBuildDate>Wed, 04 Jun 2025 18:11:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <item>
            <title><![CDATA[Review: At $349, AMD’s 16GB Radeon RX 9060 XT is the new midrange GPU to beat]]></title>
            <link>https://arstechnica.com/gadgets/2025/06/review-at-349-amds-16gb-radeon-rx-9060-xt-is-the-new-midrange-gpu-to-beat/</link>
            <guid>https://www.resetera.com/threads/review-at-349-amd%E2%80%99s-16gb-radeon-rx-9060-xt-is-the-new-midrange-gpu-to-beat.1207047/</guid>
            <content:encoded><![CDATA[https://arstechnica.com/gadgets/2025/06/review-at-349-amds-16gb-radeon-rx-9060-xt-is-the-new-midrange-gpu-to-beat/<br/><br/><div id="readability-page-1" class="page"><div id="main">
            <article data-id="2098499">
  
  <header>
  <div>
    

    

    <p>
      If that $349 price is real then it's a great deal; if it's not real, it depends.
    </p>

    

    <div id="caption-2098724">
    
    <p>
      ASRock's version of AMD's 16GB Radeon RX 9060 XT.

              <span>
          Credit:

          
          Andrew Cunningham

                  </span>
          </p>
  </div>

    <div>
    
    <p>
      ASRock's version of AMD's 16GB Radeon RX 9060 XT.

              <span>
          Credit:

          
          Andrew Cunningham

                  </span>
          </p>
  </div>
  </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>Now that most of Nvidia's GeForce RTX 50-series graphics cards have been released, it's clear that they give AMD and Intel their best opportunity this decade to claw back some market share and make the dedicated graphics card business a little less lopsided.</p>
<p>It's not that the 50-series GPUs have been&nbsp;<em>bad</em> cards, but a focus on sometimes-useful, sometimes-not AI-generated frames and a lack of major manufacturing advancements relative to the 40-series have eroded Nvidia's usual lead in performance and power efficiency.</p>
<p>That's the advantage AMD is trying to press with <a href="https://arstechnica.com/gadgets/2025/05/amds-299-radeon-rx-9060-xt-brings-8gb-or-16gb-of-ram-to-fight-the-rtx-5060/">the new Radeon RX 9060 XT graphics cards</a>, which at $299 and $349 for 8GB and 16GB are both priced and configured to comprehensively undercut Nvidia's RTX 5060 and 5060 Ti. As with the <a href="https://arstechnica.com/gadgets/2025/03/amd-radeon-rx-9070-and-9070-xt-review-rdna-4-fixes-a-lot-of-amds-problems/">RX 9070 series</a> earlier this year, the RDNA 4 architecture goes a long way toward addressing the RX 6000 and RX 7000-series' lackluster ray-tracing performance and mediocre power efficiency, and a relatively affordable 16GB version will help insulate buyers from the RAM limitations that are slowly but surely becoming more of a problem for 8GB cards.</p>
<p>With the usual 2025 GPU caveat—the difference between a "good" GPU and a "bad" one is whether you can actually find one and buy it for anything close to the list price—let's dive into one of the few genuinely exciting midrange GPUs we've gotten in a while.</p>
<h2>RX 9060 XT specs and speeds</h2>
<div><table>
<tbody>
<tr>
<th></th>
<th>RX 9070 XT</th>
<th>RX 9070</th>
<th>RX 9060 XT</th>
<th>RX 7600 XT</th>
<th>RX 7600</th>
</tr>
<tr>
<th>Compute units (Stream processors)</th>
<td>64 RDNA4 (4,096)</td>
<td>56 RDNA4 (3,584)</td>
<td>32 RDNA4 (2,048)</td>
<td>32 RDNA3 (2,048)</td>
<td>32 RDNA3 (2,048)</td>
</tr>
<tr>
<th>Boost Clock</th>
<td>2,970 MHz</td>
<td>2,520 MHz</td>
<td>3,130 MHz</td>
<td>2,755 MHz</td>
<td>2,655 MHz</td>
</tr>
<tr>
<th>Memory Bus Width</th>
<td>256-bit</td>
<td>256-bit</td>
<td>128-bit</td>
<td>128-bit</td>
<td>128-bit</td>
</tr>
<tr>
<th>Memory Bandwidth</th>
<td>650GB/s</td>
<td>650GB/s</td>
<td>320GB/s</td>
<td>288GB/s</td>
<td>288GB/s</td>
</tr>
<tr>
<th>Memory size</th>
<td>16GB GDDR6</td>
<td>16GB GDDR6</td>
<td>8 or 16GB GDDR6</td>
<td>16GB GDDR6</td>
<td>8GB GDDR6</td>
</tr>
<tr>
<th>Total board power (TBP)</th>
<td>304 W</td>
<td>220 W</td>
<td>150 (8GB) or 160 W (16GB), up to 182 W</td>
<td>190 W</td>
<td>165 W</td>
</tr>
</tbody>
</table></div>
<p>On paper, the 9060 XT series looks a lot like last generation's RX 7600 and RX 7600 XT. All of those GPUs have 32 of AMD's compute units, and all are connected to either 8GB or 16GB of GDDR6 via a 128-bit memory interface.</p>
<p>But AMD says that each RDNA4 CU is much more capable than in previous architectures—when the 9070 series was introduced, AMD said that an RDNA4 CU could render roughly twice as fast as an RDNA2 CU or 2.5 times faster for ray-tracing workloads. The RX 7600 and 7600 XT only improved over the RX 6650 XT by a few percentage points, but the 9060 XT should be a bigger upgrade.</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>The 9060 XT's Navi 44 silicon is also manufactured using a 4 nm TSMC process rather than the 6 nm process used for the 7600 series. You can already see that in the lower total board power (TBP) figures for both cards: The 16GB 9060 XT starts 30 W lower than the RX 7600 XT, and the 8GB 9060 XT starts 15 W lower than the vanilla RX 7600.</p>
<p>The cards' power consumption will vary slightly based on the settings your GPU's manufacturer uses and what settings you select in the Tuning section of the Adrenalin software. Officially, AMD publishes a range of TBP figures for the 9060 series rather than a single default number. For the 8GB card, that range runs from 150 W to 182 W; for the 16GB card, it ranges from 160 W to 182 W.</p>
<p>AMD says the 150 and 160 W baselines should represent the ideal spot on the efficiency curve, where performance-per-watt is greatest. But OEMs can choose a higher default to try to squeeze out a bit more performance, and users will generally be able to set their own GPUs to operate at the bottom or top of that TBP range using "favor efficiency" or "favor performance" buttons in the Adrenalin app.</p>
<p>As long as your card is being adequately cooled, a card with a higher TBP should be able to maintain higher clock speeds for a bit longer, boosting performance. Presumably, using a higher TBP setting will also improve the cards' overclocking headroom somewhat, but you'll also be at the mercy of the silicon lottery.</p>

<figure>
    
          <figcaption>
        <div>
    
    <p>
      The 9070 and 9060 cards both have "tuning presets" that change the maximum TBP level of the card.

              <span>
          Credit:

          
          Andrew Cunningham

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>Our ASRock review unit shipped with a default TBP of 170 W, and all of our testing reflects that slightly higher-than-baseline TBP. It only has a single 8-pin power connector, and we'd bet that most GPUs from most of AMD's partners ship the same way.</p>
<p>One nice thing for users of slightly older systems is that the 9060 XT uses a full 16-lane PCI Express 5.0 interface. The GPU does not <em>need</em> 16 lanes of PCIe 5.0 bandwidth, but older PCs that only support PCIe 4.0 or even 3.0 should still have sufficient bandwidth for it, something that has occasionally been an issue for midrange cards that have shifted to eight-lane PCIe interfaces.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<h3>Testbed notes</h3>

<p>Our gaming testbed uses the same configuration we've been using since <a href="https://arstechnica.com/gadgets/2025/01/review-nvidias-geforce-rtx-5090-is-the-first-gpu-that-can-beat-the-rtx-4090/">the RTX 5090 review</a> earlier this year. It's powered by an eight-core Ryzen 7 9800X3D processor, which is way, way more CPU than you need for any of these midrange GPUs. They will generally perform just as well with any relatively recent Intel Core i5 or AMD Ryzen 5 processor. But it ensures that the CPU is never limiting the GPU, eliminating one important variable when we see slow or otherwise weird results in our benchmarks.</p>
<p>We tested the 9060 XT mostly at 1080p and 1440p resolutions and compared it primarily to the last-generation Radeon RX 7600, 7600 XT, 7700 XT, and 9070; Nvidia's GeForce RTX 4060, 5060, and 5060 Ti; and Intel's Arc B580. Where available, we've also included some results for older cards—the GeForce RTX 3060 and 3070 and the AMD Radeon RX 6650 XT—to give people a sense of what they can expect if they haven't upgraded their GPU in a few years.</p>
<h2>Performance and power consumption</h2>


<p>The 8GB and 16GB versions of the 9060 XT are basically drop-in replacements for last generation's RX 7600 and RX 7600 XT, which, despite the "XT" in the name, were mostly the same GPU with 16GB of RAM instead of 8GB. We only had the 16GB version of the card available to test, but we can make some broad assumptions by comparing the 8GB and 16GB versions of the 7600 and seeing which games seem to struggle disproportionately with less RAM.</p>
<p>At 1440p, the 9060 XT usually runs between 22 and 62 percent faster than the RX 7600 XT in games without ray-tracing effects enabled. That's a solid generational jump that makes a strong case for the 9060 XT as an entry-level 1440p GPU. These $300–$400 GPUs have been marketed primarily as 1080p cards for a long time, and the 9060 XT will also pair well with a high-refresh-rate 1080p monitor, but people looking to play games at 1440p for less than $400 have a good option here if they can find this card at or near its list price. The 9060 XT isn't quite as fast as a last-generation RX 7700 XT (originally $449) or RX 6800 (originally $580, in 2020 dollars), but it comes pretty close.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          



<p>In games with ray-tracing effects enabled, the 9060 XT soundly beats the 7700 XT and 6800 and runs some games like <em>Cyberpunk 2077</em> around twice as fast as the old 7600 XT. Nvidia still has a small edge here—the 9060 XT is slightly faster than the RTX 5060 but slower than the 5060 Ti. But AMD has narrowed the gap quite a bit, to the extent that ray tracing isn't nearly the liability for AMD that it once was. You may or may not care about these fancy lighting effects, but some games are already beginning to require ray-tracing support, and it's likely to become more common over the next few years.</p>


<p>Compared to Nvidia's offerings, the 9060 XT sits between the $299 8GB RTX 5060 and the supposed-to-be-$429 16GB 5060 Ti. It generally outperforms the 5060 by a small but consistent margin across the board (the one exception being in <em>Black Myth Wukong</em>, where Nvidia cards still generally do better than AMD's), and it generally loses to the 5060 Ti by 10 or 15 percent. Given that 16GB 5060 Ti cards are actually going for closer to $500 right now, the 9060 XT at $349 is still a more economical choice if you can find one.</p>
<p>One important win for AMD here: The 16GB 9060 XT is usually 40 to 60 percent faster than 2021's RTX 3060. If you have one of those cards, you're probably still getting decent performance out of it. But AMD is offering&nbsp; a relatively affordable upgrade path that bumps you up from 12GB of RAM to 16GB rather than making you step down to 8GB, as both the RTX 4060 and 5060 do. If you have a 3060 and you're looking for a relatively affordable way to play more games at 1440p or at higher settings, AMD's new card might get you there.</p>


<p>As for power efficiency, the 9060 XT is a huge improvement, consuming roughly the same amount of power as the 8GB RX 7600 or Nvidia's RTX 3060 but performing considerably faster than either. The 5060 Ti still has a tiny edge here—power consumption is similar, and performance is a tiny bit better—but as with ray-tracing performance, the gap has closed enough that it's no longer a strong selling point in favor of Nvidia.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<h3>Is 8GB enough?</h3>
<p>If you frequent any of the tech YouTube channels that traffic in GPU reviews, you'd think that 8GB cards are pointless trash, junk you'd throw in a hole before you'd sully your gaming PC with it. A lot of that complaining—not all, but a lot of it—involves turning a game's resolution up to 4K and all the textures up to Ultra and then pointing out that things don't run, which is a bit like buying a Zippo lighter and complaining that it isn't a flamethrower.</p>
<p>Sure, 8GB of RAM is insufficient in these scenarios, but you're also talking about settings and resolutions that the GPUs would struggle with, even with unlimited video RAM.</p>
<p>With all of that said, we are noticing a handful of cases where Ultra settings at 1440p or even 1080p were occasionally challenging for our 8GB cards. Sometimes these issues were on-and-off; cards like the 8GB RTX 4060 would perform fine in a test like <em>Black Myth Wukong </em>on some runs but abruptly turn into a flipbook on other runs. The 8GB version of the 7060 wouldn't run the <em>Black Myth Wukong</em> benchmark at high settings in 1440p at all, and running it at 1080p eventually resulted in either slowdown or crashing midway through. <em>Cyberpunk</em> and even the somewhat less-demanding <em>Returnal</em>&nbsp;struggle more on the 8GB RX 7600 than they do on the 16GB RX 7600 XT.</p>

<p>These are edge cases in individual games, and lowering resolutions or settings resolves the issues. But if you're spending $350 to $400 or more on a GPU in 2025, you should try to avoid 8GB cards if you can. It used to be the case that these low-end-to-midrange GPUs weren't good for much above 1080p anyway, but the 5060 Ti and 9060 XT are both fast enough to be decent 1440p graphics cards when they're equipped with the right amount of RAM. Are the 8GB versions totally pointless? No. But they do leave performance on the table, and the problem will get worse over time.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<h2>The current state of the GPU market</h2>
<p>At this point in 2025's graphics card market, the issue isn't so much that mainstream cards like the 5060, 5070, or 9070 aren't available but that they are rarely available for their stated retail price. This has always been an issue with AMD, Nvidia, and Intel's board partners, who try to add things like fancy cooling, lighting, or marginal overclocks to justify raising the price. But MSRP cards are currently vanishingly rare, and it's hard to know where the 9060 XT's price will <em>actually</em>&nbsp;fall.</p>
<p>Using Newegg listings for cards that are in stock, Intel's "$249" Arc B580 is available for $299 at best. There <em>is</em> one $299 RTX 5060 from Gigabyte available, but the rest of them cost at least $320. The $349 8GB version of the RTX 5060 Ti actually starts at $390, and the $429 version starts closer to $490 new. The $549 RTX 5070 is more like $600 or $610. The $549 RX 9070 starts at $650 instead, and the $599 RX 9070 XT at $720 or more.</p>
<p>You get the picture—you can buy a lot of graphics cards, but the actual prices are somewhere in the neighborhood of $50 to $100 more than they ought to be.</p>
<p>If you're in the market for a GPU and you can actually get the 16GB version of the RX 9060 XT at $349, you should do it because it's clearly better and more future-proof than anything else available at that price, and the 5060 Ti's advantages are totally moot when it costs almost $150 more. But be aware of your other options and their actual costs if you can't find anything at the advertised list price.</p>
<h2>Conditionally great</h2>
<p>Imagine a better world with me: Companies that design and manufacture graphics cards announce new products and reveal pricing for those products, and then it's possible to go into a brick-and-mortar or online store and buy those products for the price that was originally announced. Wouldn't that be nice?</p>
<p>But that's not the world we live in, due to many factors: the <a href="https://arstechnica.com/gadgets/2025/05/chips-arent-improving-like-they-used-to-and-its-killing-game-console-price-cuts/">death of Moore's Law</a>, inflation, tariffs and general economic uncertainty, and the fact that companies can make much more money selling GPUs as AI accelerators than they can selling similar silicon to people who play video games.</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<p>I feel like a broken record because I've had to devote some portion of <em>every</em> GPU review I've done in the last six months to the Pricing and Availability Situation, but it's just unavoidable at this point. I can review this GPU and its probably-pretend retail price against a bunch of other GPUs and their pretend retail prices, but the actual pricing and availability are a mystery to me.</p>
<p>Take this for whatever it's worth: If all current-generation graphics cards were available at their advertised MSRPs, I'd say the 16GB version of the RX 9060 XT is the midrange graphics card to beat right now, a card that most people should buy instead of an RTX 5060 or RTX 5060 Ti. The $299 version with 8GB of memory is also probably fine, but it's worth the extra money to future-proof it—leave the 8GB cards to the pre-built PCs at this point.</p>
<p>What will the RX 9060 XT actually cost when the dust settles? Who knows. But at a baseline, the RTX 50-series is underwhelming, and the RX 90-series is more attractive than AMD's last couple of GPU generations have been. You're no longer accepting a big dip in power efficiency or ray-tracing performance just because you're picking an AMD card. Nvidia can still count benefits like DLSS upscaling and frame generation as advantages, but they're not <em>so</em> invaluable compared to the modern FSR equivalents that they're worth paying a ton of money for.</p>
<p>For the first time in years, AMD feels like it has a midrange GPU offering that I could recommend without caveats—with the caveat that it actually needs to be available at the price AMD is advertising.</p>
<h3>The good</h3>
<ul>
<li>Great 1080p and solid 1440p gaming performance, at least for the 16GB version.</li>
<li>Fewer trade-offs than past generations of Radeon GPUs, including much-improved power efficiency and ray-tracing performance.</li>
</ul>
<h3>The bad</h3>
<ul>
<li>8GB version will be held back by its RAM even at 1440p, and those problems will get worse rather than better over time.</li>
<li>FSR 3.1/FSR 4 and FSR frame generation are still not as widely supported as Nvidia's DLSS.</li>
</ul>
<h3>The ugly</h3>
<ul>
<li>The RAM limitations of the 8GB version.</li>
<li>The current state of the GPU market.</li>
</ul>


          
                  </div>

                  
          






  <div>
    

    <p>
      Andrew is a Senior Technology Reporter at Ars Technica, with a focus on consumer tech including computer hardware and in-depth reviews of operating systems like Windows and macOS. Andrew lives in Philadelphia and co-hosts a weekly book podcast called <a href="https://overduepodcast.com/">Overdue</a>.
    </p>
  </div>


  <p>
    <a href="https://arstechnica.com/gadgets/2025/06/review-at-349-amds-16gb-radeon-rx-9060-xt-is-the-new-midrange-gpu-to-beat/#comments" title="4 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    4 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  


  

  </div></div>]]></content:encoded>
        </item>
    </channel>
</rss>